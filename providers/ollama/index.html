
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://divagr18.github.io/memlayer/providers/ollama/">
      
      
        <link rel="prev" href="../gemini/">
      
      
        <link rel="next" href="../lmstudio/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>Ollama - Memlayer Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-BP0L927VBV"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-BP0L927VBV",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-BP0L927VBV",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    



<meta name="google-site-verification" content="sGz-Ne0V3Hmj0DCCSEjji9EwwTjr_ucUWohbWaL0sU0">


<meta name="title" content="Memlayer – The plug-and-play memory layer for smart, contextual agents">
<meta name="description"
    content="Memlayer is an open-source memory layer for local LLMs and agents — fast, persistent, embedding-based long-term memory with easy Python API.">
<meta name="keywords"
    content="memlayer, llm memory, vector store, agent memory, knowledge graph, embeddings, open source">


<meta property="og:title" content="Memlayer – Memory layer for LLMs and agents">
<meta property="og:description"
    content="Persistent long-term memory, multi-tier retrieval, noise-aware gating, and <100ms search.">
<meta property="og:type" content="website">
<meta property="og:url" content="https://divagr18.github.io/memlayer">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Memlayer – Memory layer for LLMs and agents">
<meta name="twitter:description"
    content="Persistent long-term memory, multi-tier retrieval, noise-aware gating, and <100ms search.">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ollama-local-llm-provider" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Memlayer Documentation" class="md-header__button md-logo" aria-label="Memlayer Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Memlayer Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Ollama
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Memlayer Documentation" class="md-nav__button md-logo" aria-label="Memlayer Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Memlayer Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Overview
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../API_REFERENCE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Basics
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Basics
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quickstart
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/operation_modes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Operation Modes
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basics/streaming/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Streaming
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Providers
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Providers
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../openai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OpenAI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../claude/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Claude
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemini/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Gemini
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Ollama
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Ollama
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Installation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-install-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Install Ollama
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-install-memlayer-with-ollama-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Install Memlayer with Ollama Support
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Start
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quick Start">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#start-ollama-server" class="md-nav__link">
    <span class="md-ellipsis">
      
        Start Ollama Server
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pull-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pull a Model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recommended-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recommended Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recommended Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-speed-2s-response" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Speed (&lt; 2s response)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-quality-standard" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Quality (Standard)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-best-performance" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Best Performance
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-configuration-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Configuration Example
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#operation-modes-with-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      
        Operation Modes with Ollama
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#streaming-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Streaming Support
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#complete-offline-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Offline Setup
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advanced Configuration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#custom-ollama-host" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Ollama Host
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#custom-context-window" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Context Window
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#custom-temperature" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Temperature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#custom-embedding-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Embedding Model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Tuning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hardware-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hardware Recommendations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu-acceleration" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPU Acceleration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-loading-time" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Loading Time
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#concurrent-requests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Concurrent Requests
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Troubleshooting
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#connection-refused-error" class="md-nav__link">
    <span class="md-ellipsis">
      
        "Connection refused" Error
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slow-first-response" class="md-nav__link">
    <span class="md-ellipsis">
      
        Slow First Response
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#out-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Out of Memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-download-fails" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Download Fails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embeddings-download-fails-local-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        Embeddings Download Fails (Local Mode)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#complete-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Example
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next Steps
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lmstudio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LMStudio
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Services
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Services
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../services/consolidation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Consolidation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../services/curation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Curation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Storage
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Storage
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../storage/chroma/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chroma
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../storage/networkx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    NetworkX Graph
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Tuning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Tuning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tuning/salience_threshold/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Salience Threshold
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tuning/intervals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Intervals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tuning/operation_mode/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Operation Modes (advanced)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Installation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-install-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Install Ollama
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-install-memlayer-with-ollama-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Install Memlayer with Ollama Support
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Start
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quick Start">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#start-ollama-server" class="md-nav__link">
    <span class="md-ellipsis">
      
        Start Ollama Server
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pull-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pull a Model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recommended-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Recommended Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recommended Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-speed-2s-response" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Speed (&lt; 2s response)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-quality-standard" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Quality (Standard)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-best-performance" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Best Performance
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-configuration-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Configuration Example
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#operation-modes-with-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      
        Operation Modes with Ollama
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#streaming-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Streaming Support
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#complete-offline-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Offline Setup
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advanced Configuration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#custom-ollama-host" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Ollama Host
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#custom-context-window" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Context Window
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#custom-temperature" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Temperature
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#custom-embedding-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Custom Embedding Model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Tuning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hardware-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hardware Recommendations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu-acceleration" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPU Acceleration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-loading-time" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Loading Time
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#concurrent-requests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Concurrent Requests
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Troubleshooting
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#connection-refused-error" class="md-nav__link">
    <span class="md-ellipsis">
      
        "Connection refused" Error
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slow-first-response" class="md-nav__link">
    <span class="md-ellipsis">
      
        Slow First Response
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#out-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Out of Memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-download-fails" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Download Fails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embeddings-download-fails-local-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        Embeddings Download Fails (Local Mode)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#complete-example" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Example
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next Steps
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="ollama-local-llm-provider">Ollama: Local LLM Provider</h1>
<h2 id="overview">Overview</h2>
<p>Ollama enables you to run LLMs locally on your machine, providing complete privacy and zero API costs. Memlayer's Ollama wrapper adds persistent memory capabilities to any Ollama-supported model.</p>
<p><strong>Key Benefits:</strong>
- ✅ Fully offline operation (no internet required)
- ✅ Complete data privacy (nothing leaves your machine)
- ✅ Zero API costs
- ✅ Fast inference on modern hardware
- ✅ Support for 100+ open-source models</p>
<hr />
<h2 id="installation">Installation</h2>
<h3 id="1-install-ollama">1. Install Ollama</h3>
<p><strong>macOS/Linux:</strong></p>
<pre><code class="language-bash">curl -fsSL https://ollama.com/install.sh | sh
</code></pre>
<p><strong>Windows:</strong>
Download from <a href="https://ollama.com/download">ollama.com/download</a></p>
<p><strong>Verify installation:</strong></p>
<pre><code class="language-bash">ollama --version
</code></pre>
<h3 id="2-install-memlayer-with-ollama-support">2. Install Memlayer with Ollama Support</h3>
<pre><code class="language-bash">pip install memlayer ollama
</code></pre>
<hr />
<h2 id="quick-start">Quick Start</h2>
<h3 id="start-ollama-server">Start Ollama Server</h3>
<pre><code class="language-bash">ollama serve
</code></pre>
<p>Leave this running in a terminal. Default address: <code>http://localhost:11434</code></p>
<h3 id="pull-a-model">Pull a Model</h3>
<pre><code class="language-bash">ollama pull qwen3:14b

### Basic Usage

```python
from memlayer.wrappers.ollama import Ollama

# Initialize with local model
client = Ollama(
    model=&quot;qwen3:14b,
    host=&quot;http://localhost:11434&quot;,
    user_id=&quot;alice&quot;,
    operation_mode=&quot;local&quot;  # Use local embeddings too
)

# Use like any other Memlayer client
response = client.chat([
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;My name is Alice and I work on Project Phoenix&quot;}
])
print(response)

# Later - it remembers!
response = client.chat([
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What project do I work on?&quot;}
])
print(response)  # &quot;You work on Project Phoenix&quot;
</code></pre>
<hr />
<h2 id="recommended-models">Recommended Models</h2>
<p>Since Memlayer relies on <strong>Tool Calling</strong> and <strong>JSON Extraction</strong> for memory management, you must use models capable of instruction following.</p>
<h3 id="for-speed-2s-response">For Speed (&lt; 2s response)</h3>
<ul>
<li><strong>Gemma 3 (1B–3B, Instruct)</strong> – Extremely fast, long context, very efficient.</li>
<li><strong>Instella-3B (Instruct)</strong> – New 2025 lightweight model optimized for instruction-following.</li>
<li><strong>Mistral Small 3.1 (Efficient 24B, Instruct)</strong> – Higher params but highly optimized for low-latency inference.</li>
</ul>
<h3 id="for-quality-standard">For Quality (Standard)</h3>
<ul>
<li><strong>Qwen 3 (32B, Instruct)</strong> – Excellent logic, tool use, and long context.</li>
<li><strong>Llama 4 (8B–70B, Scout/Maverick variants)</strong> – The new industry standard for local models in 2025.</li>
<li><strong>Mistral Medium 3 (~24–32B, Instruct)</strong> – Strong balance of performance and compute cost.</li>
</ul>
<h3 id="for-best-performance">For Best Performance</h3>
<ul>
<li><strong>Qwen 3 (235B-A22B hybrid)</strong> – State-of-the-art reasoning with massive context windows.</li>
<li><strong>Llama 4 Behemoth (Large-scale)</strong> – High-end open model with near GPT-4.5-class capability.</li>
</ul>
<hr />
<h2 id="configuration">Configuration</h2>
<h3 id="complete-configuration-example">Complete Configuration Example</h3>
<pre><code class="language-python">from memlayer.wrappers.ollama import Ollama

client = Ollama(
    # Model settings
    model=&quot;qwen3:14b&quot;,
    host=&quot;http://localhost:11434&quot;,

    # Memory settings
    user_id=&quot;alice&quot;,
    operation_mode=&quot;local&quot;,  # Use local embeddings

    # Storage paths
    chroma_dir=&quot;./chroma_db&quot;,
    networkx_path=&quot;./knowledge_graph.pkl&quot;,

    # Performance tuning
    max_search_results=5,
    search_tier=&quot;balanced&quot;,
    salience_threshold=0.5,

    # Ollama-specific
    temperature=0.7,
    num_ctx=4096  # Context window size
)
</code></pre>
<h3 id="operation-modes-with-ollama">Operation Modes with Ollama</h3>
<p><strong>Local mode (recommended):</strong></p>
<pre><code class="language-python">client = Ollama(
    model=&quot;qwen3:14b&quot;,
    operation_mode=&quot;local&quot;  # Local embeddings, fully offline
)
# First call: ~5-10s (loads sentence-transformer model)
# Subsequent calls: fast
</code></pre>
<p><strong>Online mode (hybrid):</strong></p>
<pre><code class="language-python">import os
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-key&quot;

client = Ollama(
    model=&quot;qwen3:14b&quot;,
    operation_mode=&quot;online&quot;  # LLM local, embeddings via OpenAI API
)
# Faster startup, but requires internet for embeddings
</code></pre>
<p><strong>Lightweight mode (fastest startup):</strong></p>
<pre><code class="language-python">client = Ollama(
    model=&quot;qwen3:14b&quot;,
    operation_mode=&quot;lightweight&quot;  # No embeddings, graph-only
)
# Instant startup, keyword-based search only
</code></pre>
<hr />
<h2 id="streaming-support">Streaming Support</h2>
<p>Ollama fully supports streaming responses:</p>
<pre><code class="language-python">from memlayer.wrappers.ollama import Ollama

client = Ollama(model=&quot;qwen3:14b&quot;, operation_mode=&quot;local&quot;)

# Stream response chunks
for chunk in client.chat([
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me about quantum computing&quot;}
], stream=True):
    print(chunk, end=&quot;&quot;, flush=True)
print()  # Newline after completion
</code></pre>
<p><strong>Performance:</strong>
- First chunk: ~1-2s (includes memory search if needed)
- Chunks: 1-5 characters each (smooth streaming)
- Knowledge extraction: background, doesn't block stream</p>
<hr />
<h2 id="complete-offline-setup">Complete Offline Setup</h2>
<p>Run Memlayer entirely offline with Ollama:</p>
<pre><code class="language-python">from memlayer.wrappers.ollama import Ollama

# Fully offline - no internet required
client = Ollama(
    model=&quot;qwen3:14b&quot;,
    host=&quot;http://localhost:11434&quot;,
    operation_mode=&quot;local&quot;,  # Local sentence-transformer for embeddings
    user_id=&quot;alice&quot;
)

# Everything runs locally:
# - LLM inference (Ollama)
# - Embeddings (sentence-transformers)
# - Vector search (ChromaDB)
# - Graph storage (NetworkX)
</code></pre>
<p><strong>First-time setup:</strong></p>
<pre><code class="language-bash"># Pull model (one-time, requires internet)
ollama pull qwen3:14b

# First Python call downloads embedding model (one-time)
# Model: all-MiniLM-L6-v2 (~80MB)
</code></pre>
<p><strong>After setup:</strong> Completely offline, no internet needed!</p>
<hr />
<h2 id="advanced-configuration">Advanced Configuration</h2>
<h3 id="custom-ollama-host">Custom Ollama Host</h3>
<pre><code class="language-python"># Remote Ollama server
client = Ollama(
    model=&quot;qwen3:14b&quot;,
    host=&quot;http://192.168.1.100:11434&quot;,  # Remote server
    operation_mode=&quot;local&quot;
)
</code></pre>
<h3 id="custom-context-window">Custom Context Window</h3>
<pre><code class="language-python">client = Ollama(
    model=&quot;qwen3:14b&quot;,
    num_ctx=8192,  # Increase context window (if model supports it)
)
</code></pre>
<h3 id="custom-temperature">Custom Temperature</h3>
<pre><code class="language-python">client = Ollama(
    model=&quot;qwen3:14b&quot;,
    temperature=0.3,  # Lower = more focused, higher = more creative
)
</code></pre>
<h3 id="custom-embedding-model">Custom Embedding Model</h3>
<pre><code class="language-python">client = Ollama(
    model=&quot;qwen3:14b&quot;,
    operation_mode=&quot;local&quot;,
    embedding_model=&quot;all-mpnet-base-v2&quot;  # Better quality, slower
)
</code></pre>
<hr />
<h2 id="performance-tuning">Performance Tuning</h2>
<h3 id="hardware-recommendations">Hardware Recommendations</h3>
<table>
<thead>
<tr>
<th>Model Size</th>
<th>RAM</th>
<th>GPU VRAM</th>
<th>Response Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>3B (llama3.2)</td>
<td>8GB</td>
<td>Optional</td>
<td>1-2s</td>
</tr>
<tr>
<td>7B (mistral)</td>
<td>16GB</td>
<td>Optional</td>
<td>2-5s</td>
</tr>
<tr>
<td>8B (llama3.1)</td>
<td>16GB</td>
<td>8GB+</td>
<td>2-5s</td>
</tr>
<tr>
<td>70B (llama3.1:70b)</td>
<td>40GB+</td>
<td>24GB+</td>
<td>5-15s</td>
</tr>
</tbody>
</table>
<h3 id="gpu-acceleration">GPU Acceleration</h3>
<p>Ollama automatically uses GPU if available (NVIDIA, AMD, Apple Silicon):</p>
<pre><code class="language-bash"># Verify GPU usage
ollama run llama3.2

# In another terminal:
nvidia-smi  # For NVIDIA GPUs
# or
rocm-smi   # For AMD GPUs
</code></pre>
<h3 id="model-loading-time">Model Loading Time</h3>
<p>First inference loads model to memory (~2-5s). Keep Ollama running to avoid reload:</p>
<pre><code class="language-bash"># Keep model loaded
ollama run llama3.2

# In another terminal/notebook, use Memlayer
# Model is already in memory, responses are instant
</code></pre>
<h3 id="concurrent-requests">Concurrent Requests</h3>
<p>Ollama handles concurrent requests efficiently:</p>
<pre><code class="language-python">import concurrent.futures

clients = [Ollama(model=&quot;llama3.2&quot;, user_id=f&quot;user{i}&quot;) 
           for i in range(5)]

with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    futures = [
        executor.submit(c.chat, [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: f&quot;Hello {i}&quot;}])
        for i, c in enumerate(clients)
    ]
    responses = [f.result() for f in futures]
</code></pre>
<hr />
<h2 id="troubleshooting">Troubleshooting</h2>
<h3 id="connection-refused-error">"Connection refused" Error</h3>
<p><strong>Problem:</strong> Ollama server not running</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash">ollama serve
</code></pre>
<h3 id="slow-first-response">Slow First Response</h3>
<p><strong>Problem:</strong> Model loading into memory</p>
<p><strong>Solution:</strong> Keep Ollama server running with model loaded:</p>
<pre><code class="language-bash">ollama run llama3.2
# Keep this terminal open
</code></pre>
<h3 id="out-of-memory">Out of Memory</h3>
<p><strong>Problem:</strong> Model too large for your hardware</p>
<p><strong>Solution:</strong> Use smaller model:</p>
<pre><code class="language-bash">ollama pull llama3.2  # 3B model, needs only 8GB RAM
</code></pre>
<h3 id="model-download-fails">Model Download Fails</h3>
<p><strong>Problem:</strong> Network issues during pull</p>
<p><strong>Solution:</strong> Retry with resume:</p>
<pre><code class="language-bash">ollama pull llama3.2  # Automatically resumes
</code></pre>
<h3 id="embeddings-download-fails-local-mode">Embeddings Download Fails (Local Mode)</h3>
<p><strong>Problem:</strong> First-time sentence-transformer download fails</p>
<p><strong>Solution:</strong> Manually download:</p>
<pre><code class="language-python">from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
# Now Memlayer will find cached model
</code></pre>
<hr />
<h2 id="complete-example">Complete Example</h2>
<pre><code class="language-python">from memlayer.wrappers.ollama import Ollama
import time

# Initialize fully offline client
client = Ollama(
    model=&quot;qwen3:14b,
    host=&quot;http://localhost:11434&quot;,
    operation_mode=&quot;local&quot;,
    user_id=&quot;alice&quot;
)

def chat(message):
    &quot;&quot;&quot;Send a message and stream the response.&quot;&quot;&quot;
    print(f&quot;\n🤖 Assistant: &quot;, end=&quot;&quot;, flush=True)
    start = time.time()

    for chunk in client.chat([
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message}
    ], stream=True):
        print(chunk, end=&quot;&quot;, flush=True)

    elapsed = time.time() - start
    print(f&quot;\n⏱️  Response time: {elapsed:.2f}s\n&quot;)

# Example conversation
print(&quot;👤 User: My name is Alice and I love hiking&quot;)
chat(&quot;My name is Alice and I love hiking&quot;)

print(&quot;👤 User: What do I like to do?&quot;)
chat(&quot;What do I like to do?&quot;)

print(&quot;👤 User: Plan a weekend activity for me&quot;)
chat(&quot;Plan a weekend activity for me&quot;)
</code></pre>
<hr />
<h2 id="next-steps">Next Steps</h2>
<ul>
<li><strong><a href="../../basics/quickstart/">Basics Quickstart</a></strong>: General getting started guide</li>
<li><strong><a href="../../basics/streaming/">Streaming Mode</a></strong>: Learn about streaming responses</li>
<li><strong><a href="../../tuning/operation_mode/">Operation Modes</a></strong>: Deep dive into local vs online modes</li>
<li><strong><a href="../../examples/05_providers/ollama_example.py">Examples</a></strong>: Complete working code</li>
<li><strong><a href="https://github.com/ollama/ollama">Ollama Docs</a></strong>: Official Ollama documentation</li>
</ul>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.sections", "navigation.expand", "navigation.indexes", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
    
  </body>
</html>